{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Market Code Prediction \n",
    "**Team Name : 404 Team Not Found**\n",
    "\n",
    "**Members : Armand Hubler, Anthony-Lee Sanchez, Aswin Subramanian Maheswaran, Daniel Rosel and Marco Celati**\n",
    "\n",
    "In this notebook, we develop a sequence-to-sequence model that transforms hourly energy consumption patterns into corresponding market codes. Our approach leverages an LSTM-based encoder-decoder architecture to handle variable-length sequences efficiently. This model can help in identifying key energy consumption trends and automatically generating market codes, paving the way for innovative applications in energy analytics and automated market insights.\n",
    "\n",
    "\n",
    "> To AVOID lengthy re-training (all was done on a Nvidia RTX 4090) our best model is [here](https://drive.google.com/file/d/1EW5SHKrBPHstoQxKnck7VUUtZsfZ-Z46/view?usp=sharing)\n",
    "\n",
    "## Setup and Dependencies\n",
    "\n",
    "First, we install required packages and import necessary libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: torchviz in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (0.0.3)\n",
      "Requirement already satisfied: torch in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: graphviz in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: six>=1.5 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from jinja2->torch) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/velocitatem/Documents/Projects/JupyterNotebooks/mlenv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib torchviz torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.utils.rnn as rnn_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Configuration\n",
    "\n",
    "For local execution we are using the following file structure:\n",
    "- AIHackathon\n",
    "    - notebooks (THIS IS THE `WORKDIR`)\n",
    "    - data (this is where we load our data from)\n",
    "\n",
    "Configure working directory and handle Google Colab integration if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_COLAB = False\n",
    "WORKDIR = \"/home/velocitatem/Documents/Projects/JupyterNotebooks/University/Third Year/AIHackathon/notebooks/\"\n",
    "if USE_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    WORKDIR = \"/content/drive/MyDrive/NTT Hackathon/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Load the datasets and perform initial preprocessing:\n",
    "- Load labeled OMIE data\n",
    "- Load filtered categories\n",
    "- Load unit list\n",
    "- Load blind dataset\n",
    "- Add temporal features\n",
    "- Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_omie_labelled = pd.read_csv(WORKDIR+'../data/df_omie_labelled.csv')\n",
    "df_filtered_cat = pd.read_csv(WORKDIR+'../data/filtered_categories.csv')\n",
    "df_unit_list = pd.read_csv(WORKDIR+'../data/unit_list.csv')\n",
    "df_blind = pd.read_csv(WORKDIR+'../data/df_omie_blind.csv')\n",
    "\n",
    "df_omie_labelled.columns = ['code','description', 'datetime', 'price', 'energy']\n",
    "df_blind.columns = ['datetime', 'price', 'energy']\n",
    "df_blind['datetime'] = pd.to_datetime(df_blind['datetime'])\n",
    "df_blind['date'] = df_blind['datetime'].dt.date\n",
    "df_blind['time'] = df_blind['datetime'].dt.time\n",
    "df_blind['day_of_week'] = df_blind['datetime'].dt.dayofweek\n",
    "df_blind['hour'] = df_blind['datetime'].dt.hour\n",
    "df_blind['is_weekend'] = (df_blind['day_of_week'] > 4).astype(int)\n",
    "df_blind['hour_sin'] = np.sin(2 * np.pi * df_blind['hour'] / 24)\n",
    "df_blind['hour_cos'] = np.cos(2 * np.pi * df_blind['hour'] / 24)\n",
    "df_blind['dow_sin'] = np.sin(2 * np.pi * df_blind['day_of_week'] / 7)\n",
    "df_blind['dow_cos'] = np.cos(2 * np.pi * df_blind['day_of_week'] / 7)\n",
    "df_blind['energy_percentile'] = df_blind.groupby('hour')['energy'].rank(pct=True)\n",
    "df_blind['price_percentile'] = df_blind.groupby('hour')['price'].rank(pct=True)\n",
    "df_blind['month'] = df_blind['datetime'].dt.month\n",
    "df_blind['day_of_month'] = df_blind['datetime'].dt.day\n",
    "# remove datetime, date\n",
    "blind_datetime = df_blind['datetime']\n",
    "df_blind = df_blind.drop(columns=['datetime','date','time'])\n",
    "df_omie_labelled['datetime'] = pd.to_datetime(df_omie_labelled['datetime'])\n",
    "df_omie_labelled['date'] = df_omie_labelled['datetime'].dt.date\n",
    "df_omie_labelled['time'] = df_omie_labelled['datetime'].dt.time\n",
    "df_omie_labelled['day_of_week'] = df_omie_labelled['datetime'].dt.dayofweek\n",
    "df_omie_labelled['hour'] = df_omie_labelled['datetime'].dt.hour\n",
    "df_omie_labelled['is_weekend'] = (df_omie_labelled['day_of_week'] > 4).astype(int)\n",
    "df_omie_labelled['hour_sin'] = np.sin(2 * np.pi * df_omie_labelled['hour'] / 24)\n",
    "df_omie_labelled['hour_cos'] = np.cos(2 * np.pi * df_omie_labelled['hour'] / 24)\n",
    "df_omie_labelled['dow_sin'] = np.sin(2 * np.pi * df_omie_labelled['day_of_week'] / 7)\n",
    "df_omie_labelled['dow_cos'] = np.cos(2 * np.pi * df_omie_labelled['day_of_week'] / 7)\n",
    "# for all data within the same hour, what percentile is a given record in for (energy)\n",
    "df_omie_labelled['energy_percentile'] = df_omie_labelled.groupby('hour')['energy'].rank(pct=True)\n",
    "df_omie_labelled['price_percentile'] = df_omie_labelled.groupby('hour')['price'].rank(pct=True)\n",
    "df_omie_labelled['month'] = df_omie_labelled['datetime'].dt.month\n",
    "df_omie_labelled['day_of_month'] = df_omie_labelled['datetime'].dt.day\n",
    "# extract numerical vale from code inot code_num\n",
    "text_encode = False\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "codele = LabelEncoder()\n",
    "# label encode code\n",
    "df_omie_labelled['code'] = codele.fit_transform(df_omie_labelled['code'])\n",
    "if text_encode:\n",
    "    df_omie_labelled['code_num'] = df_omie_labelled['code'].str.extract('(\\d+)').astype(int)\n",
    "    # extract text value from code into code_text\n",
    "    df_omie_labelled['code_text'] = df_omie_labelled['code'].str.extract('([a-zA-Z]+)')\n",
    "    # label encode code\n",
    "    df_omie_labelled['code_text'] = codele.fit_transform(df_omie_labelled['code_text'])\n",
    "# labeled remove description\n",
    "coltodrop = ['description','datetime','date','time']\n",
    "if text_encode:\n",
    "    coltodrop.append('code')\n",
    "df_omie_labelled = df_omie_labelled.drop(columns=coltodrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Class Definition (deprecated)\n",
    "\n",
    "Define a Market class to handle energy market data and calculations:\n",
    "- Track prices and energies\n",
    "- Calculate averages and totals\n",
    "- Store historical market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Market:\n",
    "    def __init__(self):\n",
    "        self.prices = []\n",
    "        self.energies = []\n",
    "        self.market_data = {}  # Store price and energy data with timestamps\n",
    "\n",
    "    def add_record(self, timestamp, price, energy):\n",
    "        \"\"\"Adds a price and energy record to the market data.\"\"\"\n",
    "        self.prices.append(price)\n",
    "        self.energies.append(energy)\n",
    "        self.market_data[timestamp] = {'price': price, 'energy': energy}\n",
    "\n",
    "    def calculate_average_price(self):\n",
    "        \"\"\"Calculates the average price of all records.\"\"\"\n",
    "        if not self.prices:\n",
    "            return 0\n",
    "        return sum(self.prices) / len(self.prices)\n",
    "\n",
    "    def calculate_total_energy(self):\n",
    "        \"\"\"Calculates the total energy of all records.\"\"\"\n",
    "        return sum(self.energies)\n",
    "\n",
    "    def get_market_summary(self):\n",
    "        \"\"\"Returns a summary of the market data.\"\"\"\n",
    "        avg_price = self.calculate_average_price()\n",
    "        total_energy = self.calculate_total_energy()\n",
    "        return {\n",
    "            'average_price': avg_price,\n",
    "            'total_energy': total_energy,\n",
    "            'number_of_records': len(self.prices)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(df):\n",
    "    \"\"\"Augments the data by adding a new column with the average price of the market at that time.\"\"\"\n",
    "    market = Market()\n",
    "    for index, row in df.iterrows():\n",
    "        price = row['price']\n",
    "        energy = row['energy']\n",
    "        market.add_record(index, price, energy)\n",
    "        market_summary = market.get_market_summary()\n",
    "        df.at[index, 'average_price'] = market_summary['average_price']\n",
    "        df.at[index, 'total_energy'] = market_summary['total_energy']\n",
    "    return df\n",
    "\n",
    "#augment_data(df_omie_labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>price</th>\n",
       "      <th>energy</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>energy_percentile</th>\n",
       "      <th>price_percentile</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.227769</td>\n",
       "      <td>0.576258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.227769</td>\n",
       "      <td>0.576258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.889167</td>\n",
       "      <td>0.576258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.227769</td>\n",
       "      <td>0.576258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.857781</td>\n",
       "      <td>0.244323</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712259</th>\n",
       "      <td>9323</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.730616</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712260</th>\n",
       "      <td>9324</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.554658</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712261</th>\n",
       "      <td>9325</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.444660</td>\n",
       "      <td>0.098097</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712262</th>\n",
       "      <td>9326</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>32.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.835635</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712263</th>\n",
       "      <td>9327</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.953679</td>\n",
       "      <td>0.583470</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712264 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code  price  energy  day_of_week  hour  is_weekend  hour_sin  \\\n",
       "0          0   0.00     0.0          3.0   0.0           0       0.0   \n",
       "1          1   0.00     0.0          3.0   0.0           0       0.0   \n",
       "2          2   0.00    46.2          3.0   0.0           0       0.0   \n",
       "3          3   0.00     0.0          3.0   0.0           0       0.0   \n",
       "4          4  -0.01    37.0          3.0   0.0           0       0.0   \n",
       "...      ...    ...     ...          ...   ...         ...       ...   \n",
       "712259  9323  -1.00    19.7          5.0  22.0           1      -0.5   \n",
       "712260  9324  -1.00     5.5          5.0  22.0           1      -0.5   \n",
       "712261  9325  -4.00     0.1          5.0  22.0           1      -0.5   \n",
       "712262  9326 -10.00    32.1          5.0  22.0           1      -0.5   \n",
       "712263  9327   0.00    90.0          5.0  22.0           1      -0.5   \n",
       "\n",
       "        hour_cos   dow_sin   dow_cos  energy_percentile  price_percentile  \\\n",
       "0       1.000000  0.433884 -0.900969           0.227769          0.576258   \n",
       "1       1.000000  0.433884 -0.900969           0.227769          0.576258   \n",
       "2       1.000000  0.433884 -0.900969           0.889167          0.576258   \n",
       "3       1.000000  0.433884 -0.900969           0.227769          0.576258   \n",
       "4       1.000000  0.433884 -0.900969           0.857781          0.244323   \n",
       "...          ...       ...       ...                ...               ...   \n",
       "712259  0.866025 -0.974928 -0.222521           0.730616          0.133371   \n",
       "712260  0.866025 -0.974928 -0.222521           0.554658          0.133371   \n",
       "712261  0.866025 -0.974928 -0.222521           0.444660          0.098097   \n",
       "712262  0.866025 -0.974928 -0.222521           0.835635          0.070496   \n",
       "712263  0.866025 -0.974928 -0.222521           0.953679          0.583470   \n",
       "\n",
       "        month  day_of_month  \n",
       "0         2.0          29.0  \n",
       "1         2.0          29.0  \n",
       "2         2.0          29.0  \n",
       "3         2.0          29.0  \n",
       "4         2.0          29.0  \n",
       "...       ...           ...  \n",
       "712259    6.0           1.0  \n",
       "712260    6.0           1.0  \n",
       "712261    6.0           1.0  \n",
       "712262    6.0           1.0  \n",
       "712263    6.0           1.0  \n",
       "\n",
       "[712264 rows x 14 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_omie_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>energy</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>energy_percentile</th>\n",
       "      <th>price_percentile</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.220046</td>\n",
       "      <td>0.586534</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.220046</td>\n",
       "      <td>0.586534</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>46.2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.906264</td>\n",
       "      <td>0.586534</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.220046</td>\n",
       "      <td>0.586534</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.887822</td>\n",
       "      <td>0.265386</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  energy  day_of_week  hour  is_weekend  hour_sin  hour_cos   dow_sin  \\\n",
       "0   0.00     0.0            5    23           1 -0.258819  0.965926 -0.974928   \n",
       "1   0.00     0.0            5    23           1 -0.258819  0.965926 -0.974928   \n",
       "2   0.00    46.2            5    23           1 -0.258819  0.965926 -0.974928   \n",
       "3   0.00     0.0            5    23           1 -0.258819  0.965926 -0.974928   \n",
       "4  -0.25    40.0            5    23           1 -0.258819  0.965926 -0.974928   \n",
       "\n",
       "    dow_cos  energy_percentile  price_percentile  month  day_of_month  \n",
       "0 -0.222521           0.220046          0.586534      6             1  \n",
       "1 -0.222521           0.220046          0.586534      6             1  \n",
       "2 -0.222521           0.906264          0.586534      6             1  \n",
       "3 -0.222521           0.220046          0.586534      6             1  \n",
       "4 -0.222521           0.887822          0.265386      6             1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove where price is 0 or energy is 0\n",
    "def remove_zeros(df):\n",
    "    return df[(df['price'] != 0) & (df['energy'] != 0)]\n",
    "df_blind = remove_zeros(df_blind)\n",
    "df_omie_labelled = remove_zeros(df_omie_labelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Series\n",
    "From our dataset we create chunks for each hour, this will give us two series within a reasonable range: (energy,codes) so for we can then match all the energy poitns to the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>price</th>\n",
       "      <th>energy</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>energy_percentile</th>\n",
       "      <th>price_percentile</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>36.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.855786</td>\n",
       "      <td>0.243624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.491442</td>\n",
       "      <td>0.243624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.779886</td>\n",
       "      <td>0.243624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.777550</td>\n",
       "      <td>0.243624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.756717</td>\n",
       "      <td>0.893208</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>9320</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>54.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.920946</td>\n",
       "      <td>0.098950</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>9321</td>\n",
       "      <td>2.33</td>\n",
       "      <td>553.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.929777</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>9323</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.625699</td>\n",
       "      <td>0.891571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>9324</td>\n",
       "      <td>0.19</td>\n",
       "      <td>44.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.883286</td>\n",
       "      <td>0.891571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>9326</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>43.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.880200</td>\n",
       "      <td>0.243624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     code  price  energy  day_of_week  hour  is_weekend  hour_sin  hour_cos  \\\n",
       "320     4  -0.01    36.4          3.0   1.0           0  0.258819  0.965926   \n",
       "323     7  -0.01     0.9          3.0   1.0           0  0.258819  0.965926   \n",
       "324     8  -0.01    23.3          3.0   1.0           0  0.258819  0.965926   \n",
       "325     9  -0.01    23.0          3.0   1.0           0  0.258819  0.965926   \n",
       "326    10   0.20    20.4          3.0   1.0           0  0.258819  0.965926   \n",
       "..    ...    ...     ...          ...   ...         ...       ...       ...   \n",
       "624  9320  -2.50    54.6          3.0   1.0           0  0.258819  0.965926   \n",
       "625  9321   2.33   553.5          3.0   1.0           0  0.258819  0.965926   \n",
       "627  9323   0.19     8.6          3.0   1.0           0  0.258819  0.965926   \n",
       "628  9324   0.19    44.3          3.0   1.0           0  0.258819  0.965926   \n",
       "630  9326  -0.01    43.2          3.0   1.0           0  0.258819  0.965926   \n",
       "\n",
       "      dow_sin   dow_cos  energy_percentile  price_percentile  month  \\\n",
       "320  0.433884 -0.900969           0.855786          0.243624    2.0   \n",
       "323  0.433884 -0.900969           0.491442          0.243624    2.0   \n",
       "324  0.433884 -0.900969           0.779886          0.243624    2.0   \n",
       "325  0.433884 -0.900969           0.777550          0.243624    2.0   \n",
       "326  0.433884 -0.900969           0.756717          0.893208    2.0   \n",
       "..        ...       ...                ...               ...    ...   \n",
       "624  0.433884 -0.900969           0.920946          0.098950    2.0   \n",
       "625  0.433884 -0.900969           0.993590          0.929777    2.0   \n",
       "627  0.433884 -0.900969           0.625699          0.891571    2.0   \n",
       "628  0.433884 -0.900969           0.883286          0.891571    2.0   \n",
       "630  0.433884 -0.900969           0.880200          0.243624    2.0   \n",
       "\n",
       "     day_of_month  \n",
       "320          29.0  \n",
       "323          29.0  \n",
       "324          29.0  \n",
       "325          29.0  \n",
       "326          29.0  \n",
       "..            ...  \n",
       "624          29.0  \n",
       "625          29.0  \n",
       "627          29.0  \n",
       "628          29.0  \n",
       "630          29.0  \n",
       "\n",
       "[110 rows x 14 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunk_dataset(df):\n",
    "    chunks = []\n",
    "    # create chunks of hourly data, 0-1, 1-2, 2-3\n",
    "    # first N records mgiht fall into the same hour then get all the records that fall into next hour\n",
    "    # create multiple subsets of the data where each subset has records with the same hour but different days and months\n",
    "    unique_hours = df['hour'].unique()\n",
    "    unique_months = df['month'].unique()\n",
    "    unique_days = df['day_of_month'].unique()\n",
    "    for month in unique_months:\n",
    "        for day in unique_days:\n",
    "            for hour in unique_hours:\n",
    "                chunk = df[(df['hour'] == hour) & (df['month'] == month) & (df['day_of_month'] == day)]\n",
    "                if not chunk.empty:\n",
    "                    chunks.append(chunk)\n",
    "    return chunks\n",
    "chunks = chunk_dataset(df_omie_labelled)\n",
    "chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_array</th>\n",
       "      <th>code_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[37.0, 1.7, 23.3, 22.3, 20.6, 30.6, 29.7, 43.7...</td>\n",
       "      <td>[4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[36.4, 0.9, 23.3, 23.0, 20.4, 31.1, 29.5, 43.2...</td>\n",
       "      <td>[4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[35.3, 0.9, 23.3, 23.8, 20.3, 30.9, 29.0, 43.0...</td>\n",
       "      <td>[4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[32.7, 1.9, 23.3, 24.2, 20.1, 30.9, 28.0, 43.5...</td>\n",
       "      <td>[4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[27.9, 3.6, 23.2, 24.5, 19.7, 31.3, 25.4, 44.0...</td>\n",
       "      <td>[4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>[98.7, 18.4, 23.3, 40.0, 44.4, 41.5, 27.0, 3.3...</td>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>[66.9, 12.0, 14.4, 40.0, 45.0, 39.7, 27.0, 5.0...</td>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>[24.8, 4.0, 4.5, 40.0, 29.8, 37.4, 27.0, 7.8, ...</td>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>[4.1, 0.1, 40.0, 37.3, 22.9, 27.0, 11.1, 20.3,...</td>\n",
       "      <td>[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>[40.0, 39.4, 21.4, 27.0, 12.1, 21.8, 20.2, 19....</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2254 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           energy_array  \\\n",
       "0     [37.0, 1.7, 23.3, 22.3, 20.6, 30.6, 29.7, 43.7...   \n",
       "1     [36.4, 0.9, 23.3, 23.0, 20.4, 31.1, 29.5, 43.2...   \n",
       "2     [35.3, 0.9, 23.3, 23.8, 20.3, 30.9, 29.0, 43.0...   \n",
       "3     [32.7, 1.9, 23.3, 24.2, 20.1, 30.9, 28.0, 43.5...   \n",
       "4     [27.9, 3.6, 23.2, 24.5, 19.7, 31.3, 25.4, 44.0...   \n",
       "...                                                 ...   \n",
       "2249  [98.7, 18.4, 23.3, 40.0, 44.4, 41.5, 27.0, 3.3...   \n",
       "2250  [66.9, 12.0, 14.4, 40.0, 45.0, 39.7, 27.0, 5.0...   \n",
       "2251  [24.8, 4.0, 4.5, 40.0, 29.8, 37.4, 27.0, 7.8, ...   \n",
       "2252  [4.1, 0.1, 40.0, 37.3, 22.9, 27.0, 11.1, 20.3,...   \n",
       "2253  [40.0, 39.4, 21.4, 27.0, 12.1, 21.8, 20.2, 19....   \n",
       "\n",
       "                                             code_array  \n",
       "0     [4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...  \n",
       "1     [4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...  \n",
       "2     [4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...  \n",
       "3     [4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...  \n",
       "4     [4, 7, 8, 9, 10, 14, 16, 17, 18, 19, 22, 24, 2...  \n",
       "...                                                 ...  \n",
       "2249  [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "2250  [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "2251  [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "2252  [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
       "2253  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17,...  \n",
       "\n",
       "[2254 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for chunk in chunks:\n",
    "    energy_array = chunk['energy'].values\n",
    "    code_array = chunk['code'].values\n",
    "    dataset.append({'energy_array': energy_array, 'code_array': code_array})\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "dataset.to_csv(WORKDIR+'../data/dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_length</th>\n",
       "      <th>code_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2254.000000</td>\n",
       "      <td>2254.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>175.364685</td>\n",
       "      <td>175.364685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>52.102660</td>\n",
       "      <td>52.102660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>228.000000</td>\n",
       "      <td>228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>265.000000</td>\n",
       "      <td>265.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy_length  code_length\n",
       "count    2254.000000  2254.000000\n",
       "mean      175.364685   175.364685\n",
       "std        52.102660    52.102660\n",
       "min        90.000000    90.000000\n",
       "25%       123.000000   123.000000\n",
       "50%       168.000000   168.000000\n",
       "75%       228.000000   228.000000\n",
       "max       265.000000   265.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['energy_length'] = dataset['energy_array'].apply(lambda x: len(x))\n",
    "dataset['code_length'] = dataset['code_array'].apply(lambda x: len(x))\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture and Training\n",
    "\n",
    "This model is a **sequence-to-sequence (Seq2Seq) model with an LSTM-based encoder-decoder architecture**, used for processing sequences of energy values (`energy_array`) and generating sequences of tokenized code (`code_array`). It includes **padding, teacher forcing, and evaluation using loss and accuracy metrics**.\n",
    "\n",
    "## **1. Data Preparation and Chronological Splitting**\n",
    "### **Why a chronological split?**\n",
    "Since sequence-to-sequence tasks often involve temporal or ordered data, the dataset is **split chronologically** to ensure that the model does not see future information during training. The split is:\n",
    "- **Train Set (70%)**: Used for learning.\n",
    "- **Validation Set (10%)**: Used for hyperparameter tuning.\n",
    "- **Test Set (20%)**: Used for final evaluation.\n",
    "\n",
    "### **Handling Variable-Length Sequences**\n",
    "- Each sequence has different lengths.\n",
    "- The dataset is **padded** so that sequences within a batch have the same length.\n",
    "- The **collate function** ensures that sequences are efficiently packed.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Defining the Dataset and DataLoader**\n",
    "The dataset consists of two sequence arrays:\n",
    "- **Source (`energy_array`)**: Sequence of energy values (continuous numbers).\n",
    "- **Target (`code_array`)**: Sequence of token indices (discrete integers representing a vocabulary).\n",
    "\n",
    "Each sample contains:\n",
    "1. **`src_tensor`** – Float tensor of shape `(seq_len, 1)`, where `seq_len` is the sequence length.\n",
    "2. **`trg_tensor`** – Long tensor of shape `(seq_len,)`, representing the tokenized target sequence.\n",
    "3. **`src_length`** – The length of the input sequence (used for padding).\n",
    "\n",
    "### **Collate Function for Efficient Batching**\n",
    "- **Padding:** Ensures that all sequences within a batch have the same length.\n",
    "- **`pack_padded_sequence` in PyTorch:** Used to efficiently handle variable-length sequences inside the LSTM.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Model Architecture**\n",
    "The model follows the classic **Encoder-Decoder framework** for sequence generation, using **LSTMs (Long Short-Term Memory networks)**.\n",
    "\n",
    "### **Encoder (Processes `energy_array`)**\n",
    "- **Input**: `energy_array` (Float Tensor of shape `(batch_size, seq_len, 1)`)\n",
    "- **Layers**:\n",
    "  - **LSTM Layer**: Encodes the sequence into a hidden state and a cell state.\n",
    "  - **`pack_padded_sequence`**: Used for efficiency in handling variable-length sequences.\n",
    "- **Output**:\n",
    "  - Final hidden state **(hidden, cell)** → Passed to the decoder.\n",
    "\n",
    "#### **Why LSTMs?**\n",
    "- They help capture long-term dependencies in sequential data, avoiding vanishing gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### **Decoder (Generates `code_array`)**\n",
    "- **Input**: A single token (integer index).\n",
    "- **Layers**:\n",
    "  - **Embedding Layer**: Converts token indices into dense vector representations.\n",
    "  - **LSTM Layer**: Takes the previous hidden state and generates a new state.\n",
    "  - **Fully Connected Layer**: Maps LSTM output to the vocabulary size.\n",
    "- **Output**:\n",
    "  - Predicted token probability distribution → Used to select the next token.\n",
    "\n",
    "#### **Teacher Forcing**\n",
    "- **During training**:\n",
    "  - With **probability 𝛾**, the decoder is forced to use the true target token as input for the next step.\n",
    "  - Otherwise, it uses its own prediction.\n",
    "- **Purpose**: Speeds up convergence but may lead to over-reliance on ground truth.\n",
    "\n",
    "---\n",
    "\n",
    "### **Full Sequence-to-Sequence Model**\n",
    "1. **Encoder processes `energy_array`** → Generates hidden states.\n",
    "2. **Decoder generates `code_array`**:\n",
    "   - Starts with the `<sos>` (start token).\n",
    "   - Iterates **one step at a time**, using previous predictions as input.\n",
    "   - Teacher forcing is used to stabilize training.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Training Process**\n",
    "### **Loss Function**\n",
    "- Uses **CrossEntropyLoss** with `ignore_index=0` (to ignore padding tokens).\n",
    "  \n",
    "### **Gradient Clipping**\n",
    "- Prevents exploding gradients with `torch.nn.utils.clip_grad_norm_`.\n",
    "\n",
    "### **Evaluation Metric**\n",
    "- **Token-level accuracy**:\n",
    "  - Compares predicted token indices with ground truth.\n",
    "  - Ignores padding tokens.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Testing & Final Evaluation**\n",
    "- Model is evaluated on the **test set** (unseen data).\n",
    "- Computes **loss & accuracy** to measure performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1523, Validation samples: 281, Test samples: 450\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. Data Preparation and Chronological Split\n",
    "# =============================================================================\n",
    "# Assume 'dataset' is your DataFrame loaded with two columns: 'energy_array' and 'code_array'.\n",
    "# The dataset is in chronological order (earliest at the top).\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "total_samples = len(dataset)\n",
    "\n",
    "# Split chronologically:\n",
    "# Last 20% for testing.\n",
    "test_size = int(0.2 * total_samples)\n",
    "train_val = dataset.iloc[:-test_size]   # first 80% for training+validation\n",
    "test_df = dataset.iloc[-test_size:]       # last 20% for testing\n",
    "\n",
    "# From the training+validation portion, use the last 12.5% of the total data (~10% overall) as validation.\n",
    "train_val_samples = len(train_val)\n",
    "val_size = int(0.125 * total_samples)  # roughly 10% of total when training+validation is 80%\n",
    "train_df = train_val.iloc[:-val_size]\n",
    "val_df = train_val.iloc[-val_size:]\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}, Validation samples: {len(val_df)}, Test samples: {len(test_df)}\")\n",
    "\n",
    "# Compute vocabulary size from the target token lists (assuming tokens are integers)\n",
    "all_tokens = [token for tokens in dataset['code_array'] for token in tokens]\n",
    "vocab_size = max(all_tokens) + 1  # Assumes tokens start at 0\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Define Dataset and DataLoader with Padding\n",
    "# =============================================================================\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        # Convert energy_array (source) to tensor of shape (seq_len, 1)\n",
    "        energy_seq = row['energy_array']\n",
    "        src_tensor = torch.tensor(energy_seq, dtype=torch.float).unsqueeze(1)\n",
    "        # Convert code_array (target) to tensor of token indices (seq_len,)\n",
    "        code_seq = row['code_array']\n",
    "        trg_tensor = torch.tensor(code_seq, dtype=torch.long)\n",
    "        src_length = len(energy_seq)\n",
    "        return src_tensor, trg_tensor, src_length\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_tensors, trg_tensors, src_lengths = zip(*batch)\n",
    "    src_padded = rnn_utils.pad_sequence(src_tensors, batch_first=True, padding_value=0.0)\n",
    "    trg_padded = rnn_utils.pad_sequence(trg_tensors, batch_first=True, padding_value=0)\n",
    "    src_lengths = torch.tensor(src_lengths, dtype=torch.long)\n",
    "    return src_padded, trg_padded, src_lengths\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = Seq2SeqDataset(train_df)\n",
    "val_dataset = Seq2SeqDataset(val_df)\n",
    "test_dataset = Seq2SeqDataset(test_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Define the Model Architecture\n",
    "# =============================================================================\n",
    "# Encoder: Processes the energy sequence.\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        # Pack the padded sequence for efficient processing.\n",
    "        packed = rnn_utils.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hidden, cell) = self.lstm(packed)\n",
    "        return hidden, cell\n",
    "\n",
    "# Decoder: Generates the code sequence.\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input_token, hidden, cell):\n",
    "        # input_token: (batch_size,)\n",
    "        input_token = input_token.unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "        embedded = self.embedding(input_token)   # Shape: (batch_size, 1, hidden_dim)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc(output.squeeze(1))  # Shape: (batch_size, output_dim)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Seq2Seq Model with Teacher Forcing\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.5):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "    def forward(self, src, src_lengths, trg):\n",
    "        \"\"\"\n",
    "        src: Tensor of shape (batch_size, src_seq_len, input_dim)\n",
    "        trg: Tensor of shape (batch_size, trg_seq_len)\n",
    "        \"\"\"\n",
    "        batch_size = src.size(0)\n",
    "        trg_seq_len = trg.size(1)\n",
    "        trg_vocab_size = self.decoder.fc.out_features\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, trg_seq_len, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src, src_lengths)\n",
    "        \n",
    "        # Assume first token is <sos> (start-of-sequence)\n",
    "        input_token = trg[:, 0]\n",
    "        \n",
    "        for t in range(1, trg_seq_len):\n",
    "            output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = np.random.rand() < self.teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input_token = trg[:, t] if teacher_force else top1\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Training Setup\n",
    "# =============================================================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "INPUT_DIM = 1            # Each energy value is a float (with an added feature dimension)\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 1\n",
    "OUTPUT_DIM = vocab_size  # Vocabulary size for code tokens\n",
    "\n",
    "encoder = Encoder(INPUT_DIM, HIDDEN_DIM, NUM_LAYERS).to(device)\n",
    "decoder = Decoder(OUTPUT_DIM, HIDDEN_DIM, NUM_LAYERS).to(device)\n",
    "model = Seq2Seq(encoder, decoder, device, teacher_forcing_ratio=0.5).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Use CrossEntropyLoss and ignore padding tokens (assumed to be index 0)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Accuracy Function\n",
    "# =============================================================================\n",
    "def compute_accuracy(predictions, targets, pad_idx=0):\n",
    "    \"\"\"\n",
    "    Computes token-level accuracy, ignoring padding tokens.\n",
    "    predictions: Tensor of shape (N, vocab_size)\n",
    "    targets: Tensor of shape (N,)\n",
    "    \"\"\"\n",
    "    predicted_tokens = predictions.argmax(dim=1)\n",
    "    mask = targets != pad_idx\n",
    "    correct = (predicted_tokens[mask] == targets[mask]).float().sum()\n",
    "    total = mask.float().sum()\n",
    "    return correct / total if total > 0 else torch.tensor(0.0)\n",
    "\n",
    "\n",
    "# Set to True to train the model\n",
    "TRAIN = True\n",
    "if TRAIN:\n",
    "    # =============================================================================\n",
    "    # 6. Training Loop with Validation (Loss & Accuracy)\n",
    "    # =============================================================================\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for src, trg, src_lengths in train_loader:\n",
    "            src = src.to(device)          # (batch_size, src_seq_len, 1)\n",
    "            trg = trg.to(device)          # (batch_size, trg_seq_len)\n",
    "            src_lengths = src_lengths.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(src, src_lengths, trg)\n",
    "            \n",
    "            # For loss/accuracy computation, ignore the first time step (start token)\n",
    "            output_dim = output.shape[-1]\n",
    "            output_reshaped = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(output_reshaped, trg_reshaped)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += compute_accuracy(output_reshaped, trg_reshaped, pad_idx=0).item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_train_acc = train_acc / len(train_loader)\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for src, trg, src_lengths in val_loader:\n",
    "                src = src.to(device)\n",
    "                trg = trg.to(device)\n",
    "                src_lengths = src_lengths.to(device)\n",
    "                \n",
    "                output = model(src, src_lengths, trg)\n",
    "                output_dim = output.shape[-1]\n",
    "                output_reshaped = output[:, 1:].reshape(-1, output_dim)\n",
    "                trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "                \n",
    "                loss = criterion(output_reshaped, trg_reshaped)\n",
    "                val_loss += loss.item()\n",
    "                val_acc += compute_accuracy(output_reshaped, trg_reshaped, pad_idx=0).item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_acc = val_acc / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # 7. Evaluation on the Test Set (Loss & Accuracy)\n",
    "    # =============================================================================\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, src_lengths in test_loader:\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            src_lengths = src_lengths.to(device)\n",
    "            \n",
    "            output = model(src, src_lengths, trg)\n",
    "            output_dim = output.shape[-1]\n",
    "            output_reshaped = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(output_reshaped, trg_reshaped)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += compute_accuracy(output_reshaped, trg_reshaped, pad_idx=0).item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    avg_test_acc = test_acc / len(test_loader)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_acc:.4f}\")\n",
    "    torch.save(model.state_dict(), WORKDIR+'seq2seq_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TUNE = False\n",
    "if RUN_TUNE:\n",
    "    import itertools\n",
    "\n",
    "    # Define hyperparameter grid for tuning\n",
    "    hidden_dims = [128, 256]\n",
    "    teacher_forcing_ratios = [0.5, 0.7, 0.9]\n",
    "    learning_rates = [0.001, 0.0005]\n",
    "    num_epochs_tuning = 5  # fewer epochs for quick tuning\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_config = None\n",
    "    best_model_state = None\n",
    "\n",
    "    for hidden_dim, teacher_forcing_ratio, lr in itertools.product(hidden_dims, teacher_forcing_ratios, learning_rates):\n",
    "        print(f\"\\nTraining with hidden_dim={hidden_dim}, teacher_forcing_ratio={teacher_forcing_ratio}, lr={lr}\")\n",
    "        \n",
    "        # Initialize new model with the given hyperparameters\n",
    "        encoder_tuned = Encoder(INPUT_DIM, hidden_dim, NUM_LAYERS).to(device)\n",
    "        decoder_tuned = Decoder(OUTPUT_DIM, hidden_dim, NUM_LAYERS).to(device)\n",
    "        model_tuned = Seq2Seq(encoder_tuned, decoder_tuned, device, teacher_forcing_ratio=teacher_forcing_ratio).to(device)\n",
    "        optimizer_tuned = optim.Adam(model_tuned.parameters(), lr=lr)\n",
    "        criterion_tuned = nn.CrossEntropyLoss(ignore_index=0)\n",
    "        \n",
    "        # Training for a few epochs to evaluate on validation set\n",
    "        for epoch in range(num_epochs_tuning):\n",
    "            model_tuned.train()\n",
    "            train_loss = 0\n",
    "            train_steps = 0\n",
    "            for src, trg, src_lengths in train_loader:\n",
    "                src = src.to(device)\n",
    "                trg = trg.to(device)\n",
    "                src_lengths = src_lengths.to(device)\n",
    "                \n",
    "                optimizer_tuned.zero_grad()\n",
    "                output = model_tuned(src, src_lengths, trg)\n",
    "                \n",
    "                output_dim = output.shape[-1]\n",
    "                output_reshaped = output[:, 1:].reshape(-1, output_dim)\n",
    "                trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "                \n",
    "                loss = criterion_tuned(output_reshaped, trg_reshaped)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model_tuned.parameters(), max_norm=1)\n",
    "                optimizer_tuned.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_steps += 1\n",
    "            \n",
    "            avg_train_loss = train_loss / train_steps\n",
    "            \n",
    "            # Validation\n",
    "            model_tuned.eval()\n",
    "            val_loss = 0\n",
    "            val_steps = 0\n",
    "            val_acc = 0\n",
    "            with torch.no_grad():\n",
    "                for src, trg, src_lengths in val_loader:\n",
    "                    src = src.to(device)\n",
    "                    trg = trg.to(device)\n",
    "                    src_lengths = src_lengths.to(device)\n",
    "                    output = model_tuned(src, src_lengths, trg)\n",
    "                    \n",
    "                    output_dim = output.shape[-1]\n",
    "                    output_reshaped = output[:, 1:].reshape(-1, output_dim)\n",
    "                    trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "                    \n",
    "                    loss = criterion_tuned(output_reshaped, trg_reshaped)\n",
    "                    val_loss += loss.item()\n",
    "                    acc = compute_accuracy(output_reshaped, trg_reshaped, pad_idx=0)\n",
    "                    val_acc += acc.item()\n",
    "                    val_steps += 1\n",
    "            \n",
    "            avg_val_loss = val_loss / val_steps\n",
    "            avg_val_acc = val_acc / val_steps\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs_tuning} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\")\n",
    "        \n",
    "        # Save the model if this configuration is better than before\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            best_val_acc = avg_val_acc\n",
    "            best_config = (hidden_dim, teacher_forcing_ratio, lr)\n",
    "            best_model_state = model_tuned.state_dict()\n",
    "            print(f\"--> New best config: hidden_dim={hidden_dim}, teacher_forcing_ratio={teacher_forcing_ratio}, lr={lr} with Val Acc {best_val_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\nBest Configuration: hidden_dim={best_config[0]}, teacher_forcing_ratio={best_config[1]}, lr={best_config[2]} with Val Acc: {best_val_acc:.4f}\")\n",
    "\n",
    "    # Optionally, save the best model state to a file\n",
    "    torch.save(best_model_state, WORKDIR+'best_seq2seq_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_MODEL = True\n",
    "# Best parameters\n",
    "hidden_dim = 256\n",
    "teacher_forcing_ratio = 0.9\n",
    "lr = 0.001\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "encoder_best = Encoder(INPUT_DIM, hidden_dim, NUM_LAYERS).to(device)\n",
    "decoder_best = Decoder(OUTPUT_DIM, hidden_dim, NUM_LAYERS).to(device)\n",
    "model_best = Seq2Seq(encoder_best, decoder_best, device, teacher_forcing_ratio=teacher_forcing_ratio).to(device)\n",
    "\n",
    "optimizer_best = optim.Adam(model_best.parameters(), lr=lr)\n",
    "criterion_best = nn.CrossEntropyLoss(ignore_index=0)\n",
    "if REBUILD_MODEL:\n",
    "\n",
    "    # Training loop with full iterations\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model_best.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for src, trg, src_lengths in train_loader:\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            src_lengths = src_lengths.to(device)\n",
    "            \n",
    "            optimizer_best.zero_grad()\n",
    "            output = model_best(src, src_lengths, trg)\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            output_reshaped = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion_best(output_reshaped, trg_reshaped)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model_best.parameters(), max_norm=1)\n",
    "            optimizer_best.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += compute_accuracy(output_reshaped, trg_reshaped, pad_idx=0).item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_train_acc = train_acc / len(train_loader)\n",
    "        \n",
    "        # Validation loop\n",
    "        model_best.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for src, trg, src_lengths in val_loader:\n",
    "                src = src.to(device)\n",
    "                trg = trg.to(device)\n",
    "                src_lengths = src_lengths.to(device)\n",
    "                \n",
    "                output = model_best(src, src_lengths, trg)\n",
    "                output_dim = output.shape[-1]\n",
    "                output_reshaped = output[:, 1:].reshape(-1, output_dim)\n",
    "                trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "                \n",
    "                loss = criterion_best(output_reshaped, trg_reshaped)\n",
    "                val_loss += loss.item()\n",
    "                val_acc += compute_accuracy(output_reshaped, trg_reshaped, pad_idx=0).item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_acc = val_acc / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    # save model\n",
    "    torch.save(model_best.state_dict(), WORKDIR+'seq2seq_model_best_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(1, 256, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(9328, 256)\n",
       "    (lstm): LSTM(256, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=9328, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = Seq2Seq(encoder_best, decoder_best, device, teacher_forcing_ratio=teacher_forcing_ratio).to(device)\n",
    "model_best.load_state_dict(torch.load(WORKDIR+'seq2seq_model_best_full.pth'))\n",
    "model_best.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4465, Test Accuracy: 0.8991\n"
     ]
    }
   ],
   "source": [
    "# now test the model\n",
    "model_best.eval()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for src, trg, src_lengths in test_loader:\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        src_lengths = src_lengths.to(device)\n",
    "        \n",
    "        output = model_best(src, src_lengths, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion_best(output_reshaped, trg_reshaped)\n",
    "        test_loss += loss.item()\n",
    "        test_acc += compute_accuracy(output_reshaped, trg_reshaped, pad_idx=0).item()\n",
    "test_loss /= len(test_loader)\n",
    "test_acc /= len(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summary of Key Features**\n",
    "✔ **Handles variable-length sequences efficiently**  \n",
    "✔ **Uses an LSTM-based Encoder-Decoder architecture**  \n",
    "✔ **Implements Teacher Forcing for stable training**  \n",
    "✔ **Uses gradient clipping to prevent instability**  \n",
    "✔ **Employs padding-aware training via `pack_padded_sequence`**  \n",
    "\n",
    "This model is well-suited for tasks involving sequential energy-to-code transformation, making it useful for applications like **symbolic regression, program synthesis, or energy pattern recognition.**\n",
    "Our best model built within 15 epoch has a test accuracy of 0.89 on completely unseen data which gives us a good amount of confidence in our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = model_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blind Dataset Prediction\n",
    "\n",
    "Process the blind dataset:\n",
    "- Generate predictions\n",
    "- Format output\n",
    "- Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[40.0, 39.4, 20.7, 27.0, 10.7, 22.2, 19.5, 18....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[28.9, 39.4, 15.2, 26.8, 5.6, 11.7, 10.7, 13.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[40.0, 39.0, 15.4, 27.0, 9.5, 22.1, 15.0, 14.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[39.6, 38.9, 15.3, 27.0, 7.6, 21.4, 15.4, 14.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[35.8, 38.8, 15.2, 27.0, 5.5, 19.0, 15.1, 14.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        energy_array\n",
       "0  [40.0, 39.4, 20.7, 27.0, 10.7, 22.2, 19.5, 18....\n",
       "1  [28.9, 39.4, 15.2, 26.8, 5.6, 11.7, 10.7, 13.0...\n",
       "2  [40.0, 39.0, 15.4, 27.0, 9.5, 22.1, 15.0, 14.2...\n",
       "3  [39.6, 38.9, 15.3, 27.0, 7.6, 21.4, 15.4, 14.1...\n",
       "4  [35.8, 38.8, 15.2, 27.0, 5.5, 19.0, 15.1, 14.2..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blind chunk\n",
    "blind_chunks = chunk_dataset(df_blind)\n",
    "blind_dataset = []\n",
    "for chunk in blind_chunks:\n",
    "    energy_array = chunk['energy'].values\n",
    "    blind_dataset.append({'energy_array': energy_array})\n",
    "blind_dataset = pd.DataFrame(blind_dataset)\n",
    "blind_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inference parameters\n",
    "SOS_TOKEN = 1 \n",
    "EOS_TOKEN = 2 \n",
    "MAX_LEN = 50   # Maximum length of the predicted sequence\n",
    "\n",
    "def predict_sequence(model, energy_seq, device, max_len=MAX_LEN, sos_token=SOS_TOKEN, eos_token=EOS_TOKEN):\n",
    "    \"\"\"\n",
    "    Given an energy sequence (list of floats), predicts a sequence of code tokens.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Convert energy_seq into a tensor with shape (seq_len, 1)\n",
    "    src_tensor = torch.tensor(energy_seq, dtype=torch.float).unsqueeze(1)  # (seq_len, 1)\n",
    "    src_length = src_tensor.size(0)\n",
    "    \n",
    "    # Add a batch dimension: (1, seq_len, 1)\n",
    "    src_tensor = src_tensor.unsqueeze(0).to(device)\n",
    "    src_length_tensor = torch.tensor([src_length], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor, src_length_tensor)\n",
    "    \n",
    "    # Start with the SOS token\n",
    "    input_token = torch.tensor([sos_token], dtype=torch.long).to(device)\n",
    "    predicted_tokens = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(input_token, hidden, cell)\n",
    "        predicted_token = output.argmax(1).item()\n",
    "        if predicted_token == eos_token:\n",
    "            break\n",
    "        predicted_tokens.append(predicted_token)\n",
    "        input_token = torch.tensor([predicted_token], dtype=torch.long).to(device)\n",
    "    \n",
    "    return predicted_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 673 entries, 0 to 672\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   energy_array  673 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 5.4+ KB\n"
     ]
    }
   ],
   "source": [
    "blind_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# now lets produce the blind dataset correctly\n",
    "# for each chunk in blind dataset, we add the predicted code array\n",
    "for chunk in blind_chunks:\n",
    "    energy_seq = chunk['energy'].values\n",
    "    maxlen = len(energy_seq)\n",
    "    predicted = predict_sequence(model, energy_seq, device, max_len=maxlen,\n",
    "                                 sos_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n",
    "    chunk['predicted_code_array'] = list(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codigo</th>\n",
       "      <th>fechaHora</th>\n",
       "      <th>PrecEuro</th>\n",
       "      <th>Energia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEVD003</td>\n",
       "      <td>2024-06-01 23:00:00</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CEVD209</td>\n",
       "      <td>2024-06-01 23:00:00</td>\n",
       "      <td>-15.00</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CEVD234</td>\n",
       "      <td>2024-06-01 23:00:00</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CEVD279</td>\n",
       "      <td>2024-06-01 23:00:00</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CEVD284</td>\n",
       "      <td>2024-06-01 23:00:00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Codigo           fechaHora  PrecEuro  Energia\n",
       "4  CEVD003 2024-06-01 23:00:00     -0.25     40.0\n",
       "5  CEVD209 2024-06-01 23:00:00    -15.00     39.4\n",
       "6  CEVD234 2024-06-01 23:00:00     -3.50     20.7\n",
       "7  CEVD279 2024-06-01 23:00:00     -0.61     27.0\n",
       "8  CEVD284 2024-06-01 23:00:00     -0.01     10.7"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the chunks back together\n",
    "blind_df = pd.concat(blind_chunks)\n",
    "# invert the label encoding\n",
    "blind_df['Codigo'] = codele.inverse_transform(blind_df['predicted_code_array'])\n",
    "blind_df = blind_df.drop(columns=['predicted_code_array', 'day_of_week', 'hour', 'is_weekend', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'energy_percentile', 'price_percentile', 'month', 'day_of_month'])\n",
    "blind_df['datetime'] = blind_datetime\n",
    "# fechaHora,PrecEuro,Energia\n",
    "colmap = {\"datetime\": \"fechaHora\", \"price\": \"PrecEuro\", \"energy\": \"Energia\", 'Codigo': 'Codigo'}\n",
    "blind_df = blind_df.rename(columns=colmap)\n",
    "blind_df = blind_df[['Codigo', 'fechaHora', 'PrecEuro', 'Energia']]\n",
    "blind_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save blind dataset\n",
    "blind_df.to_csv(WORKDIR+'../data/Challenge2_404TeamNotFound.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary we have built a model that is capable of looking at any hour of a day and the energy that was generated. This model then produces an array of the appropriate codes which belong to each energy point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
