{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import warnings\n",
    "\n",
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time Series Analysis\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from prophet import Prophet\n",
    "import timesfm\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Feature Engineering & Transformation\n",
    "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from numpy import fft\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Machine Learning Models\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# PyTorch and Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Suppress Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = timesfm.TimesFm(\n",
    "      hparams=timesfm.TimesFmHparams(\n",
    "          backend=\"gpu\",\n",
    "          per_core_batch_size=32,\n",
    "          horizon_len=128,\n",
    "          num_layers=50,\n",
    "          use_positional_embedding=False,\n",
    "          context_len=2048,\n",
    "      ),\n",
    "      checkpoint=timesfm.TimesFmCheckpoint(\n",
    "          huggingface_repo_id=\"google/timesfm-2.0-500m-pytorch\"),\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_omie_b = pd.read_csv('../../data/df_omie_blind.csv')\n",
    "df_omie_l = pd.read_csv('../../data/df_omie_labelled.csv')\n",
    "filtered_cat = pd.read_csv('../../data/filtered_categories.csv')\n",
    "unit_list = pd.read_csv('../../data/unit_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_omie_l.merge(unit_list, on='Codigo', how='left')\n",
    "data = data.merge(filtered_cat, on='Codigo', how='left')\n",
    "codes = filtered_cat['Codigo'].unique()\n",
    "data = data[data['Codigo'].isin(codes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features(df: pd.DataFrame):\n",
    "    df['fechaHora'] = pd.to_datetime(df['fechaHora'])\n",
    "    df['date'] = df['fechaHora'].dt.date\n",
    "    df['hour'] = df['fechaHora'].dt.hour\n",
    "    df['day_of_week'] = df['fechaHora'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    df['month'] = df['fechaHora'].dt.month\n",
    "    df['day_of_month'] = df['fechaHora'].dt.day\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df.sort_values(['fechaHora', 'Codigo'], inplace=True)\n",
    "    df['t'] = (df['fechaHora'] - df['fechaHora'].min()).dt.total_seconds() / 3600\n",
    "    \n",
    "    def sin_cos_features(df: pd.DataFrame, period, K, time_col='t'):\n",
    "        df = df.sort_values(['Codigo', 'fechaHora'])\n",
    "        for k in range(1, K + 1):\n",
    "            df[f'sin_{period}_{k}'] = np.sin(2 * np.pi * k * df[time_col] / period)\n",
    "            df[f'cos_{period}_{k}'] = np.cos(2 * np.pi * k * df[time_col] / period)\n",
    "        return df\n",
    "    \n",
    "    df = sin_cos_features(df, period=24, K=3)\n",
    "    \n",
    "    return df    \n",
    "\n",
    "def cyclical_features(df: pd.DataFrame):\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    return df\n",
    "        \n",
    "def interaction_features(df: pd.DataFrame):\n",
    "    df['energia_hour_sin'] = df['lag_Energia'] * df['hour_sin']\n",
    "    return df\n",
    "    \n",
    "def lags_features(df: pd.DataFrame):\n",
    "    df.sort_values(['fechaHora'], inplace=True)\n",
    "    df['lag_PrecEuro'] = df.groupby('Codigo')['PrecEuro'].shift(24*28)\n",
    "    df['lag_Energia'] = df.groupby('Codigo')['Energia'].shift(24*28)\n",
    "    df['lag_Energia'] = np.log(df['lag_Energia'] + 1)\n",
    "    df['lag1_Energia'] = df.groupby('Codigo')['lag_Energia'].shift(1)\n",
    "    df['lag24_Energia'] = df.groupby('Codigo')['lag_Energia'].shift(24)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data: pd.DataFrame):\n",
    "    data['Energia_stationary'] = data['Energia'].diff()\n",
    "    data = time_features(data)\n",
    "    data = cyclical_features(data)\n",
    "    data = lags_features(data)\n",
    "    data = interaction_features(data)\n",
    "    data = data.sort_values(['fechaHora', 'Codigo'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalEncodingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # Initialize the encoder with any desired options.\n",
    "        self.encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        self.cat_cols = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Identify categorical columns (dtype object) in the training data.\n",
    "        self.cat_cols = X.select_dtypes(include=['object']).columns\n",
    "        # Fit the encoder on the categorical columns.\n",
    "        self.encoder.fit(X[self.cat_cols])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X_transformed = X.copy()\n",
    "        if self.cat_cols is not None:\n",
    "            X_transformed[self.cat_cols] = self.encoder.transform(X_transformed[self.cat_cols])\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_features(df: pd.DataFrame):\n",
    "    df['cum_energy'] = df.groupby(['Codigo', 'date'])['lag_Energia'].cumsum()\n",
    "    return df\n",
    "\n",
    "def rolling_mean_features(df: pd.DataFrame):\n",
    "    features = ['lag_Energia', 'lag_PrecEuro']\n",
    "    groups = ['Codigo', 'Categoria']\n",
    "    times = [12, 24, 48, 168]\n",
    "    for group in groups:\n",
    "        for feature in features:\n",
    "            for time in times:\n",
    "                df[f'roll{time}_mean_{feature}'] = df.groupby(group)[feature] \\\n",
    "                    .transform(lambda x: x.rolling(window=time, min_periods=1).mean())\n",
    "    return df\n",
    "\n",
    "def ewm_features(df: pd.DataFrame):\n",
    "    features = ['lag_Energia', 'lag_PrecEuro']\n",
    "    groups = ['Codigo', 'Categoria']\n",
    "    spans = [12, 24, 48, 168]\n",
    "    for group in groups:\n",
    "        for feature in features:\n",
    "            for span in spans:\n",
    "                df[f'ewm{span}_mean_{feature}'] = df.groupby(group)[feature] \\\n",
    "                    .transform(lambda x: x.ewm(span=span, min_periods=1).mean())\n",
    "    return df\n",
    "\n",
    "def diff_features(df: pd.DataFrame):\n",
    "    features = ['lag_Energia', 'lag_PrecEuro']\n",
    "    for feature in features:\n",
    "        df[f'diff_{feature}'] = df.groupby('Codigo')[feature].diff()\n",
    "        df[f'diff_{feature}'] = df.groupby(['Codigo'])[f'diff_{feature}'].transform(lambda x: x.fillna(x.mean()))\n",
    "    return df\n",
    "\n",
    "def volatility_features(df: pd.DataFrame):\n",
    "    features = ['lag_Energia', 'lag_PrecEuro']\n",
    "    groups = ['Codigo', 'Categoria']\n",
    "    windows = [12, 24, 48, 168]\n",
    "    for group in groups:\n",
    "        for feature in features:\n",
    "            for window in windows:\n",
    "                df[f'volatility_{window}_{feature}'] = df.groupby(group)[feature] \\\n",
    "                    .transform(lambda x: x.rolling(window=window, min_periods=1).std())\n",
    "                df[f'volatility_{window}_{feature}'] = df.groupby(['Codigo'])[f'volatility_{window}_{feature}'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "    return df\n",
    "\n",
    "def fourrier_features(df: pd.DataFrame):    \n",
    "    def apply_fft(group):\n",
    "            X = fft.fft(group['lag_Energia'])\n",
    "            N = len(X)\n",
    "            group['lag_Energia_fft'] = np.abs(X) / N  # Normalize by length\n",
    "            return group\n",
    "\n",
    "    df = df.groupby('Codigo', group_keys=False).apply(apply_fft)\n",
    "    return df\n",
    "\n",
    "def frequency_power_features(df: pd.DataFrame):\n",
    "    df['power_spectrum'] = df.groupby('Codigo')['lag_Energia'].transform(lambda x: np.abs(fft.fft(x))**2 / len(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_selector = RFE(estimator=xgb.XGBRegressor(), n_features_to_select=10, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('agg_features', FunctionTransformer(agg_features)),\n",
    "    ('rolling_mean_features', FunctionTransformer(rolling_mean_features)),\n",
    "    ('ewm_features', FunctionTransformer(ewm_features)),\n",
    "    ('diff_features', FunctionTransformer(diff_features)),\n",
    "    ('volatility_features', FunctionTransformer(volatility_features)),\n",
    "    ('fourrier_features', FunctionTransformer(fourrier_features)),\n",
    "    ('frequency_power_features', FunctionTransformer(frequency_power_features)),\n",
    "    ('ordinal_encoding', OrdinalEncodingTransformer()),\n",
    "    ('rfe', rfe_selector)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transformation(x_train):\n",
    "    x_train = agg_features(x_train)\n",
    "    x_train = rolling_mean_features(x_train)\n",
    "    x_train = ewm_features(x_train)\n",
    "    x_train = diff_features(x_train)\n",
    "    x_train = volatility_features(x_train)\n",
    "    x_train = fourrier_features(x_train)\n",
    "    x_train = frequency_power_features(x_train)\n",
    "    x_train['zero_indicator'] = (x_train['lag_Energia'] == 0).astype(int)\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimesFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesFMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TimesFMModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_timesfm(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame) -> tuple:\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "        X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    elif isinstance(X_train, np.ndarray):\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    return X_train_tensor, y_train_tensor, X_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESFM_MODEL_PARAMS = {\n",
    "    'hidden_dim': 100,\n",
    "    'output_dim': 1,\n",
    "}\n",
    "\n",
    "TIMESFM_TRAIN_PARAMS = {\n",
    "    'lr': 0.01,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_timesfm(\n",
    "    X_train_tensor: torch.Tensor, \n",
    "    y_train_tensor: torch.Tensor,\n",
    "    TIMESFM_MODEL_PARAMS: dict,\n",
    "    TIMESFM_TRAIN_PARAMS: dict,\n",
    "    epochs: int = 150\n",
    "    ) -> TimesFMModel:\n",
    "\n",
    "    timesfm_model = TimesFMModel(input_dim=X_train_tensor.shape[1], **TIMESFM_MODEL_PARAMS)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(timesfm_model.parameters(), **TIMESFM_TRAIN_PARAMS)\n",
    "    \n",
    "    timesfm_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = timesfm_model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return timesfm_model\n",
    "    \n",
    "def evaluate_timesfm(timesfm_model: TimesFMModel, X_test_tensor: torch.Tensor) -> np.ndarray:\n",
    "    timesfm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_timesfm = timesfm_model(X_test_tensor).numpy().flatten()\n",
    "        \n",
    "    return y_pred_timesfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # batch_first=True makes input shape (batch, seq, feature)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states with zeros (and send to same device as x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Use the output from the final time step\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame) -> tuple:\n",
    "    selected_features = [\n",
    "        'lag1_Energia', 'lag24_Energia', 'roll24_mean_lag_Energia', 'ewm24_mean_lag_Energia',\n",
    "        'hour', 'day_of_week', 'day_of_month', 'month', 'is_weekend',\n",
    "        'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos',\n",
    "        'PrecEuro', 'cum_energy'\n",
    "    ]\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        X_train_selected = X_train[selected_features].values  \n",
    "        X_test_selected  = X_test[selected_features].values\n",
    "    elif isinstance(X_train, np.ndarray):\n",
    "        X_train_selected = X_train[:, selected_features]\n",
    "        X_test_selected  = X_test[:, selected_features]\n",
    "\n",
    "    # Add a time dimension (sequence length = 1)\n",
    "    X_train_lstm = torch.tensor(X_train_selected, dtype=torch.float32).unsqueeze(1)  \n",
    "    X_test_lstm  = torch.tensor(X_test_selected, dtype=torch.float32).unsqueeze(1)\n",
    "    y_train_lstm = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "    return X_train_lstm, y_train_lstm, X_test_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_MODEL_PARAMS = {\n",
    "    'hidden_size': 50,\n",
    "    'num_layers': 1,\n",
    "    'output_size': 1\n",
    "}\n",
    "\n",
    "LSTM_TRAIN_PARAMS = {\n",
    "    'lr': 0.01,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(\n",
    "    X_train: torch.Tensor, \n",
    "    y_train: torch.Tensor, \n",
    "    LSTM_MODEL_PARAMS: dict,\n",
    "    LSTM_TRAIN_PARAMS: dict,\n",
    "    epochs: int=150\n",
    "    ) -> LSTMModel:\n",
    "    \n",
    "    input_size = X_train.shape[2]\n",
    "    lstm_model = LSTMModel(input_size, **LSTM_MODEL_PARAMS)\n",
    "\n",
    "    criterion_lstm = nn.MSELoss()\n",
    "    optimizer_lstm = optim.Adam(lstm_model.parameters(), **LSTM_TRAIN_PARAMS)\n",
    "    \n",
    "    lstm_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer_lstm.zero_grad()\n",
    "        outputs = lstm_model(X_train)\n",
    "        loss = criterion_lstm(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer_lstm.step()\n",
    "        \n",
    "    return lstm_model\n",
    "    \n",
    "    \n",
    "def evaluate_lstm(lstm_model: LSTMModel, X_test_lstm: torch.Tensor) -> np.ndarray:\n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_lstm = lstm_model(X_test_lstm).numpy().flatten()\n",
    "    return y_pred_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_PARAMS = {\n",
    "    'n_estimators': 1000,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.01,\n",
    "    'verbosity': 0,\n",
    "    'booster': 'gbtree'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(\n",
    "    X_train: pd.DataFrame, \n",
    "    y_train: pd.Series, \n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    XGB_PARAMS: dict) -> xgb.XGBRegressor:    \n",
    "    xgb_reg = xgb.XGBRegressor(**XGB_PARAMS)\n",
    "    xgb_reg.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        verbose=False\n",
    "    )\n",
    "    return xgb_reg\n",
    "    \n",
    "def evaluate_xgb(xgb_reg: xgb.XGBRegressor, X_test: pd.DataFrame) -> np.ndarray:\n",
    "    return xgb_reg.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_PARAMS = {\n",
    "    'metric': 'mae',\n",
    "    'learning_rate': 0.04139126441377782,\n",
    "    'num_leaves': 59,\n",
    "    'max_depth': 7,\n",
    "    'min_data_in_leaf': 26,\n",
    "    'feature_fraction': 0.9999701887398744,\n",
    "    'bagging_fraction': 0.6553188710984839,\n",
    "    'bagging_freq': 6,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'verbose': -1,\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(\n",
    "    X_train: pd.DataFrame, \n",
    "    y_train: pd.Series, \n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    LGBM_PARAMS: dict\n",
    "    ) -> lgb.LGBMRegressor:    \n",
    "    lgbm_reg = lgb.LGBMRegressor(**LGBM_PARAMS)\n",
    "    lgbm_reg.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)]\n",
    "    )\n",
    "    return lgbm_reg\n",
    "    \n",
    "def evaluate_lgbm(lgbm_reg: lgb.LGBMRegressor, X_test: pd.DataFrame) -> np.ndarray:\n",
    "    return lgbm_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prophet(train: pd.DataFrame, TARGET: str) -> pd.DataFrame:\n",
    "    train_prophet = train.reset_index()\n",
    "    train_prophet['ds'] = pd.to_datetime(train_prophet['fechaHora'])\n",
    "\n",
    "    train_prophet = train_prophet.rename(columns={TARGET: 'y'})\n",
    "\n",
    "    return train_prophet[['ds', 'y', 'lag_PrecEuro', 'lag_Energia']]\n",
    "\n",
    "def train_prophet(train_prophet: pd.DataFrame) -> Prophet:\n",
    "\n",
    "    prophet_model = Prophet()\n",
    "    prophet_model.add_regressor('lag_PrecEuro')\n",
    "    prophet_model.add_regressor('lag_Energia')\n",
    "\n",
    "    prophet_model.fit(train_prophet)\n",
    "    \n",
    "    return prophet_model\n",
    "\n",
    "def evaluate_prophet(prophet_model: Prophet, test: pd.DataFrame) -> np.ndarray:\n",
    "\n",
    "    test_prophet = test.reset_index()\n",
    "    test_prophet['ds'] = pd.to_datetime(test_prophet['fechaHora'])\n",
    "    future = test_prophet[['ds', 'lag_PrecEuro', 'lag_Energia']]\n",
    "\n",
    "    # Forecast\n",
    "    forecast = prophet_model.predict(future)\n",
    "    return forecast['yhat'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Rolling Window CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rolling_window_cv(data: pd.DataFrame, initial_train_window: int, forecast_horizon: int, step: int):\n",
    "    \"\"\"\n",
    "    Custom rolling window cross-validation.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    train_end = initial_train_window  \n",
    "    while (train_end + forecast_horizon) <= n:\n",
    "        train_idx = list(range(0, train_end))\n",
    "        test_idx = list(range(train_end, train_end + forecast_horizon))\n",
    "        yield train_idx, test_idx\n",
    "        train_end += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique_codes = data['Codigo'].nunique()\n",
    "INITIAL_TRAIN_WINDOW = 24*28*nunique_codes\n",
    "FORECAST_HORIZON = 24*28*nunique_codes\n",
    "STEP = 24*7*nunique_codes\n",
    "\n",
    "data.drop('Descripcion', axis=1, inplace=True)\n",
    "\n",
    "EXCLUDED_COLS = ['date', 'fechaHora', 'Energia', 'Energia_stationary', 'PrecEuro']\n",
    "NUM_FEATURES = [col for col in data.select_dtypes(include=np.number).columns if col not in EXCLUDED_COLS]\n",
    "CAT_FEATURES = [col for col in data.select_dtypes(exclude=np.number).columns if col not in EXCLUDED_COLS]\n",
    "FEATURES = NUM_FEATURES + CAT_FEATURES\n",
    "\n",
    "for col in CAT_FEATURES:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "TARGET = 'Energia_stationary'\n",
    "\n",
    "model_names = ['TimesFM', 'XGB', 'LGBM', 'Prophet']\n",
    "\n",
    "results = {model: {'mae': [], 'mape': []} for model in model_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[FEATURES].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_score(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def mape_score(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.abs(y_true) + 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, test_idx) in enumerate(custom_rolling_window_cv(data, INITIAL_TRAIN_WINDOW, FORECAST_HORIZON, STEP)):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "    \n",
    "    # Split the data into train and test folds\n",
    "    train = data.iloc[train_idx]\n",
    "    test = data.iloc[test_idx]\n",
    "    \n",
    "    # Common splits for models that require X and y inputs:\n",
    "    X_train = train[FEATURES]\n",
    "    y_train = train[TARGET]\n",
    "    X_test = test[FEATURES]\n",
    "    y_test = test[TARGET]\n",
    "    \n",
    "    # X_train = feature_transformation(X_train)\n",
    "    # X_test = feature_transformation(X_test)\n",
    "    \n",
    "    # ordinal_encoder = OrdinalEncodingTransformer()\n",
    "    # X_train = ordinal_encoder.fit_transform(X_train)\n",
    "    # X_test = ordinal_encoder.transform(X_test)\n",
    "        \n",
    "    # X_train = pd.DataFrame(X_train, columns=X_train.columns.tolist())\n",
    "    # X_test = pd.DataFrame(X_test, columns=X_test.columns.tolist())\n",
    "    \n",
    "    # --------------------------\n",
    "    if 'Prophet' in model_names:\n",
    "        data_prophet = prepare_prophet(train, TARGET)\n",
    "        prophet_model = train_prophet(data_prophet)\n",
    "        y_pred_prophet = evaluate_prophet(prophet_model, test)\n",
    "        \n",
    "        mae_prophet = mae_score(y_test, y_pred_prophet)\n",
    "        mape_prophet = mape_score(y_test, y_pred_prophet)\n",
    "        \n",
    "        results['Prophet']['mae'].append(mae_score(y_test, y_pred_prophet))\n",
    "        results['Prophet']['mape'].append(mape_prophet)\n",
    "        \n",
    "        print(f\"Prophet    --> MAE: {mae_prophet:.4f}, MAPE: {mape_prophet:.4f}\")\n",
    "    \n",
    "    # --------------------------\n",
    "    if 'XGB' in model_names:\n",
    "        xgb_model = train_xgb(X_train, y_train, X_test, y_test, XGB_PARAMS)\n",
    "        y_pred_xgb = evaluate_xgb(xgb_model, X_test)\n",
    "        \n",
    "        mae_xgb = mae_score(y_test, y_pred_xgb)\n",
    "        mape_xgb = mape_score(y_test, y_pred_xgb)\n",
    "        \n",
    "        results['XGB']['mae'].append(mae_xgb)\n",
    "        results['XGB']['mape'].append(mape_xgb)\n",
    "        \n",
    "        print(f\"XGBoost    --> MAE: {mae_xgb:.4f}, MAPE: {mape_xgb:.4f}\")\n",
    "    \n",
    "    # --------------------------\n",
    "    if 'LGBM' in model_names:\n",
    "        lgb_train = lgb.Dataset(X_train, label=y_train, categorical_feature=CAT_FEATURES)\n",
    "        lgb_val = lgb.Dataset(X_test, label=y_test, categorical_feature=CAT_FEATURES)\n",
    "        \n",
    "        # lgbm_model = train_lgbm(X_train, y_train,  X_test, y_test, LGBM_PARAMS)\n",
    "\n",
    "        lgbm_model = lgb.train(\n",
    "            LGBM_PARAMS,\n",
    "            lgb_train,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[lgb_train, lgb_val],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "        )\n",
    "        \n",
    "\n",
    "        y_pred_lgbm = evaluate_lgbm(lgbm_model, X_test)\n",
    "\n",
    "        mae_lgbm = mae_score(y_test, y_pred_lgbm)\n",
    "        mape_lgbm = mape_score(y_test, y_pred_lgbm)\n",
    "\n",
    "        results['LGBM']['mae'].append(mae_lgbm)\n",
    "        results['LGBM']['mape'].append(mape_lgbm)\n",
    "\n",
    "        print(f\"LightGBM   --> MAE: {mae_lgbm:.4f}, MAPE: {mape_lgbm:.4f}\")\n",
    "\n",
    "    # --------------------------\n",
    "    if 'TimesFM' in model_names:\n",
    "        X_train_timesfm, y_train_timesfm, X_test_timesfm = prepare_timesfm(X_train, y_train, X_test)          \n",
    "        timesfm_model = train_timesfm(X_train_timesfm, y_train_timesfm, TIMESFM_MODEL_PARAMS, TIMESFM_TRAIN_PARAMS)\n",
    "        y_pred_timesfm = evaluate_timesfm(timesfm_model, X_test_timesfm)\n",
    "        mae_timesfm = mae_score(y_test, y_pred_timesfm)\n",
    "        mape_timesfm = mape_score(y_test, y_pred_timesfm)\n",
    "        \n",
    "        results['TimesFM']['mae'].append(mae_timesfm)\n",
    "        results['TimesFM']['mape'].append(mape_timesfm)\n",
    "        \n",
    "        print(f\"TimesFM   --> MAE: {mae_timesfm:.4f}, MAPE: {mape_timesfm:.4f}\")\n",
    "    \n",
    "    # --------------------------\n",
    "    # LSTM Model (PyTorch)\n",
    "    # --------------------------\n",
    "    if 'LSTM' in model_names:\n",
    "        X_train_lstm, y_train_lstm, X_test_timesfm = prepare_lstm(X_train, y_train, X_test)\n",
    "        lstm_model = train_lstm(X_train_lstm, y_train_lstm, LSTM_MODEL_PARAMS, LSTM_TRAIN_PARAMS)\n",
    "        y_pred_lstm = evaluate_lstm(lstm_model, X_test_timesfm)\n",
    "        \n",
    "        mae_lstm = mae_score(y_test, y_pred_lstm)\n",
    "        mape_lstm = mape_score(y_test, y_pred_lstm)\n",
    "        \n",
    "        results['LSTM']['mae'].append(mae_lstm)\n",
    "        results['LSTM']['mape'].append(mape_lstm)\n",
    "        \n",
    "        print(f\"LSTM       --> MAE: {mae_lstm:.4f}, MAPE: {mape_lstm:.4f}\")\n",
    "    \n",
    "# --------------------------\n",
    "# STEP 5: Aggregate and Display Results\n",
    "# --------------------------\n",
    "benchmark_results = []\n",
    "for model in model_names:\n",
    "    avg_mae = np.mean(results[model]['mae'])\n",
    "    avg_mape = np.mean(results[model]['mape'])\n",
    "    benchmark_results.append({\n",
    "        'Model': model,\n",
    "        'MAE': avg_mae,\n",
    "        'MAPE': avg_mape\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(benchmark_results)\n",
    "print(\"\\n===== Benchmark Results =====\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_PARAMS = {\n",
    "    'n_estimators': 1000,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.01,\n",
    "    'verbosity': 0,\n",
    "    'booster': 'gbtree'\n",
    "}\n",
    "\n",
    "# Convert 'fechaHora' column to datetime\n",
    "data['fechaHora'] = pd.to_datetime(data['fechaHora'])\n",
    "\n",
    "# Split the data such that the test set represents the last 3 months\n",
    "split_date = pd.to_datetime('2024-05-01')\n",
    "train = data[data['fechaHora'] < split_date]\n",
    "test = data[data['fechaHora'] >= split_date]\n",
    "\n",
    "EXCLUDED_COLS = ['fechaHora', 'Energia', 'Energia_stationary']\n",
    "FEATURES = [col for col in data.columns if col not in EXCLUDED_COLS]\n",
    "TARGET = 'Energia_stationary'\n",
    "\n",
    "# Common splits for models that require X and y inputs:\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "X_test  = test[FEATURES]\n",
    "y_test  = test[TARGET]\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train, y_train)\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "xgb_model = train_xgb(X_train, y_train, X_test, y_test, XGB_PARAMS)\n",
    "y_pred_xgb = evaluate_xgb(xgb_model, X_test)\n",
    "\n",
    "mae_xgb = mae_score(y_test, y_pred_xgb)\n",
    "mape_xgb = mape_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost    --> MAE: {mae_xgb:.4f}, MAPE: {mape_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(X_train, pd.DataFrame):\n",
    "    feature_names = X_train.columns.tolist()\n",
    "    # Create a DataFrame with feature names and their importance scores\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': xgb_model.feature_importances_\n",
    "    })\n",
    "\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "    print(importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
